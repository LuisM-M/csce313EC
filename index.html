<!DOCTYPE html>
<html lang="en">
    <link rel="stylesheet" href="index.css">
    <h1>
        Exploring the Supercomputers at TAMU
    </h1>
    <body>
        <h1>Supercomputers In General</h1>
        <h2> Supercomputer History</h2>
        <p> The idea of the supercomputer was first proposed in the late 1950s when the US government began funding the development of high performance computers for military use. It wasn&prime;t until the early 1960s when supercomputers were introduced. IBM announced the creation of their 7030 Stretch and Sperry Rand revealed the UNIVAC LARC. This was when history was made as these two computers would go onto become the first two intentional supercomputers made in history. Although it was initially produced for military applications, supercomputers quickly found themselves being applied by companies in the industrial and commercial fields. In fact, the CDC 6600, which was designed by Seymour Cray, is considered to be the first successful supercomputer made for commercial purposes. A great power struggle began as companies fought to be at the forefront of the commercial supercomputer industry and it wasn&prime;t until the 1990s that IBM took reins as the leader and continue to do so today.</p>

        <h2> What is a supercomputer?</h2>
        <p> Supercomputers are a type of computer that manages to operate at extremely fast speeds most notably due to their use of more than one CPU. This use of multiple processors also allows them to store vast amounts of data compared to normal computers. Their extremely quick speeds and processing power allow programmers to make use of them to handle complicated tasks that would not be possible with normal computers.</p>

        <h2> What is supercomputing used for?</h2>
        <p> There are many reasons why supercomputers are used today. They are useful when it comes to machine learning, deep learning, and artificial intelligence. When it comes to machine learning, IBM has been able to use it to predict anti-cancer drug sensitivity. This means that IBM can simulate how cancer cells will react to certain drugs through the use of Multimodal-attention-based neural networks. Deep learning can be used to help chemists by exploring the endless combinations of chemical compounds so that they can discover the next material structure that is environmentally friendly or superior to the materials we use today. Finally, IBM has found ways for supercomputers to help combat the spread of COVID-19. 
            IBM has lended a hand to researchers and have offered them a surplus of computing power that can be used for finding treatments and cures. They can run a huge amount of calculations that help expedite calculations and experiments. 
            </p>

        <h2> How is the speed measured?</h2>
        <p> Supercomputing is measured in floating point operations per second (FLOPS) and petaflops are a measure of a computer&prime;s processing speed equal to a thousand trillion flops. In general, a supercomputer can have a million times more processing power than a normal laptop. The 3 fastest supercomputers in the world are Japan&prime;s Figaku, which is clocked at a speed of 442 petaflops, and IBM&prime;s Summit and Sierra, which were clocked at 148.8 and 94.6 petaflops respectively.</p>

        <h2> Texas A&M Supercomputers</h2>
        <p> Texas A&M University is currently in possession of three supercomputers. They are called FASTER, Grace, and Terra. A&M has had at least one supercomputer running on campus since 1989, and replaces them every few years so that they are running at optimal performance. Their newest supercomputer, Grace, is said to be A&M&prime;s most powerful one yet. It was primarily developed by DELL. These computers are primarily used for research purposes, but access is also given to students in case they want to try them out or compute a large set of data. The next supercomputer in development is called ACES, and is a collaboration between A&M and other universities. </p>

        <h2> Supercomputers with other computing types</h2>
        <p> Supercomputers are used in high-performance computing (HPC), which is a device that uses many supercomputers to process complex and large calculations. Supercomputers are also sometimes referred to as parallel computers because they have the ability to use parallel processing, which is when you have many different CPUs that are all being used to solve a single calculation at a certain time. HPCs also have the ability to use parallelism.</p>

        <h2> Definitions for Computer Hardware Terms</h2>
        <p> In the following section, we will go more into detail about A&M&prime;s 3 supercomputers and list some of their hardware specs. There are several common components that will be discussed, and they will be defined in the following list:
        </p>
        <p>
            &bull; Compute nodes: Commonly used in virtual machines, they are what link a VM to physical hardware such as CPU and Memory. In general, the more of these a VM has access to the faster it can run. 
        </p>

        <p>
            &bull; Computer cores: These cores make up a CPU and are what generally handle tasks that are sent to the CPU. The more cores that a CPU has, the more instructions it can execute in a given time.
        </p>

        <p>
            &bull; Interconnect: This handles the connection and data transfer between physical or virtual devices. In this case, it refers to the connection between a host computer and one of A&M’s supercomputers. 
        </p>

        <p>
            &bull;  Global Disk: This is a type of storage that organizes data or file systems so they can be accessed by multiple different computers.
        </p>


        <h1> Grace</h1>
        <img src="media/Grace.jpg" />
        <h2> Hardware </h2>
        <p> Grace is currently A&M&prime;s most powerful supercomputer, and possesses some extremely impressive hardware specifications. It is named after computer scientist Grace Hopper. Grace Hopper was also a pioneer in the technology field and also had an important career in the U.S. Navy. Hopper was a strong advocate for the use of COBOL in the Navy and helped spread the use of COBOL in the 1960s. Like Terra and FASTER, it runs on a linux operating system. According to TAMU, it contains 44,656 cores and 925 nodes. Most computers only have around 4 cores, so this is a significant improvement in processing power. Its peak performance is 6.2 PFLOPS. This means it is capable of performing 6.2 quadrillion floating point operations per second. It contains roughly 8 PB of total usable disc space, which equates to about 8000000 gigabytes of total data storage.It is currently housed at the West Campus Data Center, and was installed in Spring 2021. This means it will likely be replaced for a newer super computer sometime in 2025. 
        </p>

        <h2> File Systems</h2>
        <p> Grace is organized between a home file system and a scratch file system. The home system is the default area the user uses when logging in. This handles regular operations that are not too complex. Data stored here is regularly backed up for safekeeping. The scratch section is capable of handling much larger amounts of data. However, it cannot be used to hold data for long periods of time since it would be impractical to hold such large amounts of data indefinitely. The data in this area is also not backed up like the home area is, so you can potentially lose data if an error occurs. Grace is also capable of handling moderate levels of data transfer, but large data transfers may be difficult due to transfers potentially getting interrupted. </p>

        <h1> Terra</h1>
        <img src="media/Terra.jpg" />
        <h2> Hardware</h2>
        <p> The Terra supercomputer is a supercomputer that was produced at Texas A&M in February 2017. In latin, Terra means “this planet” or “Earth”. One of the reasons for the creation of Terra was to study images from an Earth Observation Satellite (EOS), which is why it was named Terra. It has 9,632 total cores, as well as a total of 320 compute nodes and 3 login nodes. There are also 256 compute nodes with 64 GB of memory, 48 compute nodes with 128 GB of memory and a K80 graphics processing unit (GPU) card. Nodes on Terra either have 64 GB or 128 GB of RAM and it tries to minimize its memory usage because too many memory requests will be rejected by SLURM. Terra runs on the Linux CentOS 7 operating system. The global disk uses Lenovo's DSS-G260 to create 7 petabytes of global storage across the entire system. This supercomputer is located at the Teague Data Center at Texas A&M University. For reference, this is about a half a mile from the Memorial Student Center on campus. Terra consists of a fabric made of a two level fat tree that is primarily based on the Omni-Path Architecture, which is a system that handles communication. The Terra supercomputer was clocked at 377 TFLOPs, which is its peak performance rate.
        </p>

        <h2> File Systems</h2>
        <p> Terra&prime;s global file space is split up into two file systems, the Home and Scratch file systems. The Home file system, which has an environment variable named $HOME, uses the DSS-G260 storage hardware. It also has a file space quota of 10 GB and file counts quota of 10000. The main purpose of the Home file system is from a small amount of processing because its space and file count limits are very constricted. This is also why it is saved every night, because it is easy to fill up that space. On the other hand, the Scratch file system has an environment variable name of $SCRATCH, but it also uses the DSS-G260 storage hardware. However, it has a lot more storage space as its file space quota is a whopping 1 TB and its file count quota is 250000. Unlike the Home file system, the Scratch file system is built as a high performance system that is meant to hold large files for short periods of time and only for processes that are using it at that time. It is important to note that nothing will be backed up with the Scratch file system because it is not meant to be used as a large term storage unit. This is why it is important to clear the system of unnecessary items whenever possible.
        </p>

        <h1> FASTER</h1>
        <img src="media/faster.jpg" />
        <h2> Hardware</h2>
        <p> The FASTER supercomputer at Texas A&M University is a supercomputer that has a total of 11,520 cores and 180 nodes. It runs on Linux, or more specifically, it has CentOS 8 installed. CentOS is an operating system that provides an open-source computing platform. This supercomputer resides in the West Campus Data center which is 1.7 miles from the Memorial Student Center. The FASTER supercomputer was produced in 2021 and it has a peak performance of 1.2 PFLOPS (Peta Floating Point Operations Per Second). FASTER is a 184-node Dell x86 HPC Cluster that also has an InfiniBand HDR-10 interconnect. While its peak performance is not as robust as Grace or Terra, it is superior to an everyday laptop or pc. </p>

        <h2> File Systems</h2>
        <p> FASTER has a global file space that is accessible on every node. The two main file systems are the Scratch and Home file systems. The Home directory is listed as: “/home/USERID” and the Scratch directory is separated into two directories including: “/scratch/user/USERID” and “/scratch/group/PROJECTID”. 
            The home directory has a File Space Quota of 10 Gigabytes and a File Count Quota of 10,000. This directory is used for computations that are not too complex. One key thing to note is that it is regularly backed up during the night.
            On the other hand, the first Scratch directory has a File Space Quota of 1 Terabyte and a File Count Quota of 250,000. This directory performs at a higher level due to its increased storage. This storage allows the user to store larger files for a brief amount of time. In contrast to the previous directory, it does not get backed up frequently. The current directory is used for storing files for an extended amount of time.
            The second Scratch directory has a File Space Quota of 5 Terabytes and a File Count Quote of 500,000. The last storage can only be accessed upon unique requests. The files in this directory have to be purged after 90 days.
            Something interesting about the FASTER supercomputer is the process for transferring files. The High Performance Research Computing Wiki states that one can use MobaXterm or WinSCP for transferring files from FASTER to a Windows machine.
            
            </p>

        <h1> Overall</h1>
        <h2> Batch Summary</h2>
        <p> The three supercomputers use the Slurm system to control batch jobs. This handles all background processes that the user does not interact with. The user is able to create new jobs using the Slurm format. When creating a job through Slurm, one must set numerous parameters such as a name, task count, and wall clock limit (WCL). The WCL value determines how long a job can run before it is killed. There are also other optional parameters that can be set for a job such as an email notification, general resource, and setting temporary disc space. After setting all of these specifications, there must be a list of the executable commands that will be used for the job. Once this is complete, a Slurm file can be submitted with the sbatch command, which will finish creating the job. Jobs can subsequently be monitored through various commands that allow the user to view the status of a job and kill it if necessary. Batch queues are used to schedule all running jobs, and do so based on their significant parameters such as WCL. The user can also check the status of the queues. If the WCL is reached for a job, its progress can be saved and resumed later without having to restart completely.</p>

        <h2> Compiling and Running Programs</h2>
        <p> There are numerous compilers supported such as icpc and ifort. When invoked numerous flags can be passed to modify their behavior, such as changing the name of the resulting executable and skipping linking. One can also modify the compiler’s optimization settings that can tell the compiler to use more invasive optimization techniques and attempt to implement parallel programming to speed up the execution. OpenMP code can be compiled using settings that allow parallel code to be executed efficiently. MPI code can be compiled in a similar manner, with support for compilers such as gcc and g++.
        </p>

        <h1> Work Cited</h1>
        <p> &bull; “Texas A&M High Performance Research Computing.” High Performance Research Computing, https://hprc.tamu.edu/.</p>
        <p> &bull; “What Is Supercomputing?” IBM, https://www.ibm.com/topics/supercomputing. </p>
        <p> &bull; “Novel Ai Tools to Accelerate Cancer Research.” IBM Research Blog, 28 Nov. 2019, https://www.ibm.com/blogs/research/2019/07/ai-tools-for-cancer-research/. </p>
        <p> &bull; Henton, Lesley. “A More Powerful Supercomputer for Texas A&M Research Is Coming Soon.” Texas A&M Today, 9 Nov. 2020, https://today.tamu.edu/2020/11/09/a-more-powerful-supercomputer-for-texas-am-research-is-coming-soon/#:~:text=Texas%20A%26M%20purchased%20its%20first,on%20the%20College%20Station%20campus. </p>
        <p> &bull; Takeda, Seiji. “Supercharging New Materials Design with AI and Hybrid Cloud.” IBM Research Blog, IBM, 12 Aug. 2022, https://research.ibm.com/blog/ibm-molecule-generation-experience. </p>
        <p> &bull; “IBM Helps Bring Supercomputers into the Global Fight against COVID-19.” IBM Newsroom, https://newsroom.ibm.com/IBM-helps-bring-supercomputers-into-the-global-fight-against-COVID-19. </p>
        <p> &bull; Mohan, Vinod. “What Is Global Namespace: Manage Your Unstructured Data.” DataCore Software, 28 Apr. 2021, https://www.datacore.com/blog/what-is-global-namespace-file-object-storage/. </p>
        <p> &bull; “Core Processor.” Core Processor - an Overview | ScienceDirect Topics, https://www.sciencedirect.com/topics/computer-science/core-processor.</p>
        <p> &bull; “What Is Interconnection?” Netnod, https://www.netnod.se/ix/what-is-interconnection. </p>
        <p> &bull; About Compute Nodes, https://techlibrary.hpe.com/docs/enterprise/servers/cloudsystem/webhelp/content/s_about-vmhost-isc.html#:~:text=A%20compute%20node%20provides%20the,created%20in%20VMware%20vCenter%20Server. </p>
        <p> &bull; “Grace Murray Hopper (1906-1992): A Legacy of Innovation and Service.” YaleNews, 18 Nov. 2021, https://news.yale.edu/2017/02/10/grace-murray-hopper-1906-1992-legacy-innovation-and-service. </p>
        <p> &bull; The Centos Project, https://www.centos.org/. </p>
    </body>
</html>
